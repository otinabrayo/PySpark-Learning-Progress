# PySpark Learning Progress

## Overview
This repository documents my learning journey in PySpark. Below is a list of topics I have covered so far.

## Topics Covered

### Data Reading
- Reading JSON files
- Reading CSV files

### Schema Definition
- Defining schemas using `StructType`

### Data Transformation
- Selecting columns using `select()`
- Renaming columns with `alias()` and `withColumnRenamed()`
- Filtering data using `filter()`
- Adding new columns with `withColumn()`
- Changing data types with `cast()`
- Sorting data using `sort()` / `order()`
- Limiting rows using `limit()`
- Dropping columns with `drop()`
- Removing duplicate rows with `dropDuplicates()`

### Data Operations
- Merging data using `union()` and `unionByName()`

## Next Steps
I plan to explore more advanced PySpark functionalities, including:
- Joins and aggregations
- Window functions
- Performance optimization techniques

## How to Use
This repository will contain example scripts demonstrating these concepts. Stay tuned for updates!

## Contributions
Feel free to fork the repository and contribute by adding examples, optimizations, or new topics.

